{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (6.29.5)\n",
      "Requirement already satisfied: appnope in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (8.36.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.13.2)\n",
      "Requirement already satisfied: wcwidth in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/greatdaveo/CODE_BASE/ML-Course/venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Lang smith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x10d4d9f00> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10d4da530> root_client=<openai.OpenAI object at 0x10d4db6d0> root_async_client=<openai.AsyncOpenAI object at 0x10d4db220> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence systems designed to generate new content, such as text, images, audio, or other data, that resembles existing data. Unlike traditional AI, which typically focuses on analyzing or predicting outcomes based on input data, generative AI creates data, often with a focus on creativity or content generation. \\n\\nSome key characteristics and methods associated with generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These involve two neural networks, a generator and a discriminator, that are trained together. The generator creates data, while the discriminator evaluates it against real data to distinguish between genuine and synthetic outputs, gradually improving the quality of generated content.\\n\\n2. **Variational Autoencoders (VAEs):** These are used for generating new data by encoding input data into a latent space and decoding it back with added variation, enabling the creation of new, similar data.\\n\\n3. **Transformer models:** Models like GPT (Generative Pre-trained Transformer) are prominent in text generation. These large language models are capable of producing human-like text by predicting and generating text sequences based on input prompts.\\n\\n4. **Neural Style Transfer:** This technique involves re-imagining an image in the style of another, blending content and style to create entirely new artistic renditions.\\n\\nGenerative AI has a wide range of applications, including creating art and music, developing realistic images and video content, designing products and environments, and even assisting in drug discovery and other scientific research. Its ability to mimic human creativity holds transformative potential across industries, but it also raises ethical and societal challenges, such as content authenticity, copyright issues, and the potential for misuse.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 338, 'prompt_tokens': 13, 'total_tokens': 351, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CMrMI53Q96Y9gdcvT3bBb41avtmTU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f0707cbd-d1b8-4dfa-a917-249e6fc15288-0' usage_metadata={'input_tokens': 13, 'output_tokens': 338, 'total_tokens': 351, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a suite of tools specifically designed for developing with large language models (LLMs) and AI agents. It offers functionalities to help developers trace and evaluate LLM and agent applications, improving their performance and reliability. Key features include robust tools for testing and debugging code involving LLMs, monitoring their performance in real-world scenarios, and continuously refining interactions with the models to meet application needs effectively. Langsmith can be particularly useful for developers looking to optimize their use of AI technologies, ensuring models are both efficient and aligned with desired outcomes.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 33, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CMrMOSOn8SipqMCjlebCziDfxKEzm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8c89b4e3-3a9f-487c-8cb9-3f0a1df00f03-0' usage_metadata={'input_tokens': 33, 'output_tokens': 108, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Chain \n",
    "chain = prompt|llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain, designed to enhance the development, deployment, and evaluation of language model applications. It provides a set of features that streamline the process of application creation through thoughtful tracking and assessment mechanisms.\n",
      "\n",
      "Key aspects of Langsmith include:\n",
      "\n",
      "1. **Tracing and Evaluation Framework**: Langsmith enables developers to trace the interactions within language model applications, allowing for detailed visibility into how the models process input and generate output. This is crucial for debugging and optimizing performance.\n",
      "\n",
      "2. **Testing and Monitoring**: The platform offers tools to continuously test and monitor applications once they are deployed, ensuring they perform reliably and meet defined quality standards.\n",
      "\n",
      "3. **Feedback Loop**: Langsmith facilitates the integration of user feedback and iterative improvements, enabling developers to refine applications based on real-world usage and evaluation metrics.\n",
      "\n",
      "In summary, Langsmith aims to simplify and improve the workflow for developers working with language models, ensuring applications are robust, effective, and aligned with user expectations.\n"
     ]
    }
   ],
   "source": [
    "# str output Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
